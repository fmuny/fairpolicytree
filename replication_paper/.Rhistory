data_list[[set_name]]$exp,
compute_welfare(Dstar_opt_out, scores_org_out),
compute_cramerv(Dstar_opt_out, sens_comb_org_out$sens_comb),
compute_chi2(Dstar_opt_out, sens_comb_org_out$sens_comb),
compute_BF(Dstar_opt_out, sens_comb_org_out$sens_comb),
compute_prog_freq(Dstar_opt_out - 1))
}
# Print results
for (name in names(results_list)) {
cat(paste0(tools::toTitleCase(name), " sample:\n"))
print(round(results_list[[name]], 3))
cat("\n")
}
# Plot the trees
lab <- mappings[!is.na(mappings[VAR_D_NAME]), 'X']
plot(opt_tree_list[['pt_unadj_inclS']], leaf.labels=lab)
plot(opt_tree_list[['pt_unadj_exclS']], leaf.labels=lab)
plot(opt_tree_list[['pt_adjust_A']], leaf.labels=lab)
plot(opt_tree_list[['pt_adjust_score']], leaf.labels=lab)
plot(opt_tree_list[['pt_adjust_A_score']], leaf.labels=lab)
plot(opt_tree_list[['pt_adjust_Acdf']], leaf.labels=lab)
plot(opt_tree_list[['pt_adjust_Acdf_score']], leaf.labels=lab)
# --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
# ------------ Run & evaluate probabilistic split trees ------------------------
# --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
# Fit probabilistic split tree
data_list2 <- list(
pst_adjust_A = list(exp = TRUE, adjust_scores = FALSE),
pst_adjust_A_score = list(exp = TRUE, adjust_scores = TRUE))
for(set_name in names(data_list2)) {
opt_tree <- prob_split_tree(
As_org,
scores_org,
sens_org,
adjust_scores=data_list2[[set_name]]$adjust_scores,
seed=SEED,
ties.method=TIES_METHOD,
depth=PT_DEPTH,
search.depth=PT_SEARCH_DEPTH,
split.step=splitstep,
min.node.size=minnodesize)
opt_tree_list[[set_name]] <- opt_tree
Dstar_opt <- predict(opt_tree, As_org, sens_org, seed=SEED)
Dstar_opt_out <- predict(opt_tree, As_org_out, sens_org_out, seed=SEED)
results_list$training[set_name, ] <- c(
data_list2[[set_name]]$exp,
compute_welfare(Dstar_opt, scores_org),
compute_cramerv(Dstar_opt, sens_comb_org$sens_comb),
compute_chi2(Dstar_opt, sens_comb_org$sens_comb),
compute_BF(Dstar_opt, sens_comb_org$sens_comb),
compute_prog_freq(Dstar_opt - 1))
results_list$evaluation[set_name, ] <- c(
data_list2[[set_name]]$exp,
compute_welfare(Dstar_opt_out, scores_org_out),
compute_cramerv(Dstar_opt_out, sens_comb_org_out$sens_comb),
compute_chi2(Dstar_opt_out, sens_comb_org_out$sens_comb),
compute_BF(Dstar_opt_out, sens_comb_org_out$sens_comb),
compute_prog_freq(Dstar_opt_out - 1))
}
# Print results
for (name in names(results_list)) {
cat(paste0(tools::toTitleCase(name), " sample:\n"))
print(round(results_list[[name]], 3))
cat("\n")
}
# Plot the trees
plot(opt_tree_list[['pst_adjust_A']], sens_names=VAR_S_NAME_ORD, leaf.labels=lab)
plot(opt_tree_list[['pst_adjust_A_score']], sens_names=VAR_S_NAME_ORD, leaf.labels=lab)
# Combine to one tree by manually adjusting dot string
for(set_name in names(data_list2)) {
dot_string_total <- ""
j <- 0
for(i in names(opt_tree_list[[set_name]])){
j <- j + 1
dot_string2 <- plot(opt_tree_list[[set_name]][[i]], leaf.labels=lab)[["x"]][["diagram"]]
dot_string2 <- gsub("\n(\\d)", paste0("\n",j,"\\1"), dot_string2)
dot_string2 <- gsub("-> (\\d)", paste0("-> ",j,"\\1"), dot_string2)
dot_string2 <- sub("digraph nodes { \n node [shape=box] ;\n", "", dot_string2, fixed = TRUE)
dot_string2 <- sub("\n}", "", dot_string2, fixed = TRUE)
dot_string2 <- gsub("[labeldistance=2.5, labelangle=45, headlabel=\"True\"]", "", dot_string2, fixed = TRUE)
dot_string2 <- gsub("[labeldistance=2.5, labelangle=-45, headlabel=\"False\"]", "", dot_string2, fixed = TRUE)
dot_string_total <- paste0(dot_string_total, dot_string2)
}
dot_string <- paste0("
digraph combined {
rankdir=LR;
node [shape=box];
top [label=\"female = 1\", shape=ellipse, style=filled, fillcolor=lightblue];
top2 [label=\"swiss = 1\", shape=ellipse, style=filled, fillcolor=lightblue];
top3 [label=\"swiss = 1\", shape=ellipse, style=filled, fillcolor=lightblue];
", dot_string_total, "
top -> top2 [labeldistance=3, labelangle=-30, headlabel='True'];
top -> top3 [labeldistance=3, labelangle=30, headlabel='False'];
top2 -> ", 10, ";
top2 -> ", 20, ";
top3 -> ", 30, ";
top3 -> ", 40, ";
}
")
dot_string <- gsub("qual_degree", "degree", dot_string, fixed = TRUE)
dot_string <- gsub("past_income", "past earnings", dot_string, fixed = TRUE)
print(DiagrammeR::grViz(dot_string))
if(save){
DiagrammeR::grViz(dot_string) %>%
DiagrammeRsvg::export_svg() %>%
charToRaw() %>%
rsvg::rsvg_pdf(paste0(RESULTS_PATH, set_name, "_extleft.pdf"))
}
}
# Additional checks:
# Run exact version to ensure that is really exactly the same
plot(opt_tree_list[['pt_adjust_Acdf']], leaf.labels = lab)
# Transform the tree thresholds
opt_tree_org_Acdf_trans <- fairpolicytree:::transform_tree(
tree=opt_tree_list[['pt_adjust_Acdf']],
sens=sens_org,
vars=As_org,
vars_cdf=As_cdf
)
# Return predicted nodes to compare to org res
nodes_org_Acdf_trans_check <- fairpolicytree:::transform_tree(
tree=opt_tree_list[['pt_adjust_Acdf']],
sens=sens_org,
vars=As_org,
vars_cdf=As_cdf,
return_nodes=TRUE
)
print("Distribution of predicted final nodes in org_res_trans")
print(table(nodes_org_Acdf_trans_check))
# Compare to nodes from residualized tree
nodes <- predict(opt_tree_list[['pt_adjust_Acdf']], As_cdf, type="node.id")
print("Distribution of predicted final nodes in org_res")
print(table(nodes))
# Same result!
# Check that equal for all observations
all.equal(nodes, nodes_org_Acdf_trans_check)
# Evaluate at new thresholds using exact version
idx_sens <- names(opt_tree_org_Acdf_trans)
Dstar_org_Acdf_transform_exact <- nodes_org_Acdf_trans_check*NA
for(sens in idx_sens){
A_values <- as.numeric(unlist(strsplit(sens, "_")))
if(length(A_values) == 1) {
bool <- training_fair_df[VAR_S_NAME_ORD][, 1] == A_values
} else {
bool <- apply(training_fair_df[VAR_S_NAME_ORD][, seq_along(
A_values)], 1, function(row) all(row == A_values))
}
filtered_df <- subset(training_fair_df[VAR_A_NAME_ORD], bool)
filtered_df_Acdf <- subset(training_fair_df[paste0(VAR_A_NAME_ORD, "_cdf")], bool)
Dstar_org_Acdf_transform_exact[bool] <- predict(
opt_tree_org_Acdf_trans[[sens]], filtered_df, opt_tree_list[['pt_adjust_Acdf']], filtered_df_Acdf)
}
# Exact method gives exactly the same result as pt_adjust_Acdf
print(sum(predict(opt_tree_list[['pt_adjust_Acdf']], As_cdf) != Dstar_org_Acdf_transform_exact))
# --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
# ------------ Export results table to latex -----------------------------------
# --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
for (name in names(results_list)) {
sample_txt <- if(name=="evaluation") "out-of-sample" else "in-sample"
results_export_out <- results_list[[name]]
# Select columns to export
cols_to_export <- c(
"observed",
"blackbox",
"blackboxfair",
"allin1",
"pt_unadj_inclS",
"pt_unadj_exclS",
"pt_adjust_A",
"pt_adjust_score",
"pt_adjust_A_score",
"pst_adjust_A",
"pst_adjust_A_score" )
results_export_out <- results_export_out[cols_to_export,]
policies <- data.frame(Policy = c(
"Observed",
"Blackbox",
"Blackbox fair",
"All in one",
"Unadjusted incl. $S$",
"Unadjusted excl. $S$",
"Adjust $A$",
"Adjust $\\Gamma_{d}$",
"Adjust $A$ and $\\Gamma_{d}$",
"Adjust $A$",
"Adjust $A$ and $\\Gamma_{d}$"
))
results_export_out <- cbind(policies, data.frame(results_export_out, row.names=NULL))
colnames(results_export_out) <- c(
"\\textbf{Policy}", "\\textbf{Interp.}", "\\textbf{Welfare}", "CramerV",
"p-value", "log(BF)", "NP", "JS", "VC", "CC", "LC", "EP")
# Manually adjust columns
results_export_out <- results_export_out %>%
mutate(`\\textbf{Welfare}` = round(as.numeric(`\\textbf{Welfare}`), 3),
`CramerV` = round(as.numeric(`CramerV`), 3),
`p-value` = round(as.numeric(`p-value`), 3),
`log(BF)` = round(as.numeric(`log(BF)`), 3),
`\\textbf{Interp.}` = ifelse(`\\textbf{Interp.}` == 1, "True", "False"),)
#Transform treatment shares to percentages
results_export_out <- results_export_out %>%
mutate(across(
.cols = (ncol(results_export_out)-nunique_D+1):ncol(results_export_out),
.fns = ~ ifelse(is.na(as.numeric(.)), NA, sprintf("%.1f\\%%", round(as.numeric(.) * 100, 2)))
))
results_export_out[["log(BF)"]] <- format(round(results_export_out[["log(BF)"]], 0), nsmall = 0)
note = paste(
"\\\\setstretch{1}\\\\scriptsize \\\\textit{Notes:} This table presents measures of interpretability,",
"welfare, and fairness for various policy types.",
"The column labeled \\\\textit{Interp.} indicates whether the policy is interpretable. The \\\\textit{Welfare} column reports",
"the mean potential outcome under the assignments of the respective policy. The next three columns",
"display fairness metrics: Cramer's V, its associated p-value, and the logarithm of the Bayes Factor.",
"The remaining columns report the resulting program shares under each policy, with \\\\textit{NP} = No Program,",
"\\\\textit{JS} = Job Search, \\\\textit{VC} = Vocational Course, \\\\textit{CC} = Computer Course,",
"\\\\textit{LC} = Language Course, \\\\textit{EP} = Employment Program."
)
if(name=="evaluation"){
note <- paste(note, "Statistics are computed out-of-sample using data not used for estimating policy scores or training the policy tree.")
}
results_export_out_latex <- kable(results_export_out, format = "latex", escape = FALSE, booktabs=T,
caption = paste0("Welfare-Fairness-Interpretability trade-off for different policies (", sample_txt,")"),
label = paste0("tab:main_results_", substr(sample_txt,1,2)), align='llrrrrrrrrrr', full_width = T) %>%
kable_styling(latex_options = c("HOLD_position"), font_size = 8) %>%
add_header_above(c(" " = 3, "Fairness" = 3, "Program shares" = 6), bold = T, line=T) %>%
pack_rows("Benchmark policies", 1, 4) %>%
pack_rows(paste0("Optimal policy tree (depth ", PT_DEPTH, ")"), 5, 9) %>%
pack_rows(paste0("Probabilistic split tree (depth ", PT_DEPTH, ")"), 10, 11) %>%
# column_spec(6, width = "2cm") %>%
footnote(general = note, footnote_as_chunk=T, general_title="", threeparttable = T, escape = FALSE)
writeLines(results_export_out_latex, paste0(RESULTS_PATH, "main_results_", substr(sample_txt,1,2), ".tex"))
}
# --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
# ------------ Partial adjustments ---------------------------------------------
# --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
# Get grid from 0 to 1 by 0.1 steps
# get weighted combinations of score and As
# Run policy trees
# Compute stats and plot
weights <- seq(0,1,0.1)
inv_weights <- 1 - weights
As_weight <- mapply(function(w, iw) round(As_mq * w + As_org * iw, 0), weights, inv_weights, SIMPLIFY = FALSE)
As_weight_out <- mapply(function(w, iw) round(As_mq_out * w + As_org_out * iw, 0), weights, inv_weights, SIMPLIFY = FALSE)
scores_weight <- mapply(function(w, iw) scores_mq * w + scores_org * iw, weights, inv_weights, SIMPLIFY = FALSE)
As_org_list <- replicate(length(weights), As_org, simplify = FALSE)
As_org_out_list <- replicate(length(weights), As_org_out, simplify = FALSE)
scores_org_list <- replicate(length(weights), scores_org, simplify = FALSE)
scenarios <- list(
clean_As = list(As = As_weight, scores = scores_org_list, As_out = As_weight_out),
clean_Scores = list(As = As_org_list, scores = scores_weight, As_out = As_org_out_list),
clean_Scores_As = list(As = As_weight, scores = scores_weight, As_out = As_weight_out)
)
rows <- list()
opt_tree_weight <- list()
for(scen in names(scenarios)){
As_list <- scenarios[[scen]]$As
Scores_list <- scenarios[[scen]]$scores
As_out_list <- scenarios[[scen]]$As_out
opt_tree_weight[[scen]] <- list()
for(i in seq_along(weights)){
print(paste0(scen, ": ", i))
opt_tree_weight[[scen]][[i]] <- tree_FUN(As_list[[i]], Scores_list[[i]])
Dstar <- predict(opt_tree_weight[[scen]][[i]], As_out_list[[i]])
rows[[length(rows) + 1]] <- data.frame(
Weight = weights[i],
Metric='Welfare',
Scenario=scen,
Value=compute_welfare(Dstar, scores_org_out))
rows[[(length(rows) + 1)]] <- data.frame(
Weight = weights[i],
Metric='CramerV',
Scenario=scen,
Value=compute_cramerv(Dstar, sens_comb_org_out$sens_comb)[[1]])
}
}
results_partial <- do.call(rbind, rows)
range_Welfare <- results_partial %>% filter(Metric == "Welfare") %>%
summarise(min_val = floor(min(Value) * 10) / 10, max_val = ceiling(max(Value) * 10) / 10)
range_CramerV <- results_partial %>% filter(Metric == "CramerV") %>%
summarise(min_val = floor(min(Value) * 10) / 10, max_val = ceiling(max(Value) * 10) / 10)
# Plot
p1 <- ggplot(results_partial[results_partial$Metric == "Welfare", ], aes(x = Weight, y = Value, color = Scenario, linetype= Scenario)) +
geom_line(linewidth=0.7) +
labs(title = "Welfare", x = "Weight of adjusted variable", color = "Scenario:", linetype= "Scenario:") +
ylim(range_Welfare$min_val, range_Welfare$max_val) +
theme_minimal() +
scale_color_discrete(labels = c(expression(paste("Adjust ", A)), expression(paste("Adjust ", Gamma["d"])), expression(paste("Adjust ", A, " and ", Gamma["d"])))) +
scale_linetype_discrete(labels = c(expression(paste("Adjust ", A)), expression(paste("Adjust ", Gamma["d"])), expression(paste("Adjust ", A, " and ", Gamma["d"]))))
p2 <- ggplot(results_partial[results_partial$Metric == "CramerV", ], aes(x = Weight, y = Value, color = Scenario, linetype= Scenario)) +
geom_line(linewidth=0.7) +
labs(title = "Fairness (Cramer's V)", x = "Weight of adjusted variable", color = "Scenario:", linetype= "Scenario:") +
ylim(0, range_CramerV$max_val) +
theme_minimal() +
scale_color_discrete(labels = c(expression(paste("Adjust ", A)), expression(paste("Adjust ", Gamma["d"])), expression(paste("Adjust ", A, " and ", Gamma["d"])))) +
scale_linetype_discrete(labels = c(expression(paste("Adjust ", A)), expression(paste("Adjust ", Gamma["d"])), expression(paste("Adjust ", A, " and ", Gamma["d"]))))
plot_combined <- (p1 + p2) + plot_layout(guides = "collect")
if(save){
ggsave(paste0(RESULTS_PATH, "partial_adjustment.pdf"),
plot = plot_combined, width = 7.5, height = 2.5, units = "in")
}
# --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
# ------------ Check winners and loosers ---------------------------------------
# --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --
# Function to compute individual welfare
individual_welfare <- function(Dstar, scores) {
scores[cbind(seq_along(Dstar), Dstar)]
}
# Function to generale cluster labels
generate_cluster_labels <- function(means) {
labels <- character(length(means))
gains <- means > 0
losses <- means < 0
zeros <- means == 0
intensity_labels <- c("Strong", "Moderate", "Mild", "Slight")
# Gains
if(sum(gains) > 0){
ranks <- rank(-means[gains], ties.method = "first")
intensity <- if(sum(gains) > 1) paste(intensity_labels[seq_along(ranks)], "Gain") else "Gain"
labels[gains] <- intensity[order(ranks)]
}
# Losses
if(sum(losses) > 0){
ranks <- rank(means[losses], ties.method = "first")
intensity <- if(sum(losses) > 1) paste(intensity_labels[seq_along(ranks)], "Loss") else "Loss"
labels[losses] <- intensity[order(ranks)]
}
# No change
labels[zeros] <- "No Change"
return(labels)
}
#Selection short table
vars_short <- c(
"welfare_diff",
"n",
"female",
"swiss",
"age",
"past_income",
"qual_degree",
"conton_moth_tongue",
"emp_share_last_2yrs",
"emp_spells_5yrs",
"married",
"other_mother_tongue",
"ue_spells_last_2yrs",
"city_1",
"city_2",
"city_3"
)
# Adjust variable names
map_varnames <- c(
"welfare_diff" = "Welfare difference",
"n" = "Number of observations in cluster",
"female" = "Job seeker is female",
"swiss" = "Swiss citizen",
"age" = "Age of job seeker",
"canton_moth_tongue" = "Mother tongue in canton's language",
"cw_age" = "Age of caseworker",
"cw_cooperative" = "Caseworker cooperative",
"cw_educ_above_voc" = "Caseworker education: above vocational training",
"cw_educ_tertiary" = "Caseworker education: tertiary track" ,
"cw_female" = "Caseworker female",
"cw_missing" = "Indicator for missing caseworker characteristics",
"cw_own_ue" = "Caseworker has own unemployemnt experience",
"cw_tenure" = "Caseworker job tenure in years",
"cw_voc_degree" = "Caseworker education: vocational training degree",
"emp_share_last_2yrs" = "Fraction months employed in last 2 years",
"emp_spells_5yrs" = "Employment spells in last 5 years",
"employability" = "Employability as assessed by the caseworker",
"foreigner_b" = "Foreigner with temporary permit (B permit)",
"foreigner_c" = "Foreigner with permanent permit (C permit)",
"gdp_pc" = "Cantonal GDP per capita (in CHF 10,000)",
"married" = "Job seeker is married",
"other_mother_tongue" = "Mother tongue other than German, French, Italian",
"past_income" = "Earnings in CHF before unemployment",
"ue_cw_allocation1" = "Allocation of unemployed to caseworkers: by industry",
"ue_cw_allocation2" = "Allocation of unemployed to caseworkers: by occupation",
"ue_cw_allocation3" = "Allocation of unemployed to caseworkers: by age",
"ue_cw_allocation4" = "Allocation of unemployed to caseworkers: by employability",
"ue_cw_allocation5" = "Allocation of unemployed to caseworkers: by region",
"ue_cw_allocation6" = "Allocation of unemployed to caseworkers: other",
"ue_spells_last_2yrs" = "Unemployment spells in last 2 years",
"unemp_rate" = "Cantonal unemployment rate (in %)",
"city_3" = "Lives in big city",
"city_2" = "Lives in medium city",
"city_1" = "Lives in no city",
"prev_job_sec_cat_0" = "Sector of last job: tertiary sector",
"prev_job_sec_cat_1" = "Sector of last job: secondary sector",
"prev_job_sec_cat_2" = "Sector of last job: missing sector",
"prev_job_sec_cat_3" = "Sector of last job: primary sector",
"prev_job_0" = "Previous job: skilled worker",
"prev_job_1" = "Previous job: manager",
"prev_job_2" = "Previous job: unskilled worker",
"prev_job_3" = "Previous job: self-employed",
"qual_0" = "Qualification: with degree",
"qual_1" = "Qualification: semiskilled",
"qual_2" = "Qualification: unskilled",
"qual_3" = "Qualification: no degree",
"qual_degree" = "Qualification: with degree"
)
kmeans_results <- list()
# Implement for both versions of prob split trees
for(set_name in names(data_list2)) {
kmeans_results[[set_name]] <- list()
# Prepare data
data_df <- cbind(
evaluation_df[, columns$X_ord[columns$X_ord > 0]],
fastDummies::dummy_cols(
data.frame(lapply(evaluation_df[, columns$X_unord[columns$X_unord > 0]], as.character)),
remove_selected_columns = TRUE
),
welfare_adjusted = individual_welfare(
predict(tree = opt_tree_list[[set_name]], A = As_org_out, sens = sens_org_out),
scores_org_out
),
welfare_unadjusted = individual_welfare(
predict(opt_tree_list[["pt_unadj_exclS"]], As_org_out),
scores_org_out
)
)
# Compute the difference between actual and reference welfare.
data_df$welfare_diff <- data_df$welfare_adjusted - data_df$welfare_unadjusted
welfare_diff_matrix <- matrix(data_df$welfare_diff, ncol = 1)
# Determine optimal number of clusters using Silhouette score
dist_matrix <- stats::dist(welfare_diff_matrix)
min_cluster_size <- ceiling(nrow(data_df) / 100)
sil_width <- sapply(2:8, function(k){
km <- kmeans(welfare_diff_matrix, centers = k, nstart = 10)
ss <- silhouette(km$cluster, dist_matrix)
if(min(km$size) > min_cluster_size){
mean(ss[, 3])
}else{
0
}
})
n_clusters <- which.max(sil_width) + 1
# Get clusters ordered by cluster mean
km <- kmeans(welfare_diff_matrix, centers = n_clusters, nstart = 10)
ordered_clusters <- order(km$centers)
cluster_map <- setNames(seq_along(ordered_clusters), ordered_clusters)
data_df$cluster_ids <- cluster_map[as.character(km$cluster)]
# Get variables means
df_grouped_means <- data_df %>%
group_by(cluster_ids) %>%
summarise(n = n(), across(where(is.numeric),\(x) mean(x, na.rm = TRUE)))  %>%
pivot_longer(cols = -cluster_ids, names_to = "variable", values_to = "mean") %>%
pivot_wider(names_from = cluster_ids, values_from = mean) %>%
arrange(factor(variable, levels = c("welfare_diff", setdiff(variable, "welfare_diff")))) %>%
mutate(across(where(is.numeric), round, 2))
colnames(df_grouped_means) <- c("Variable", generate_cluster_labels(
round(as.numeric(subset(df_grouped_means, variable == 'welfare_diff')[, -1]),2)))
add <- if(set_name=="pst_adjust_A_score") " and policy scores" else ""
note <- paste0(
"\\\\setstretch{1}\\\\scriptsize \\\\textit{Notes:} ",
"The table shows mean values of variables within clusters obtained via k-means clustering. ",
"Clustering is based on the difference in welfare between optimal policy trees with ",
"adjustment (of decision variables",
add,
") and without adjustments. The number of clusters is determined in a data-driven ",
"way by the Silhouette score and the minimum required cluster size is set to 1\\\\% of the observations.")
# Loop through numeric columns
df_grouped_means <- as.data.frame(df_grouped_means)
for (col in names(df_grouped_means)[-1]) {
df_grouped_means[[col]] <- ifelse(
df_grouped_means$Variable %in% c("n", "past_income"),
formatC(df_grouped_means[[col]], format = "f", digits = 0),
formatC(df_grouped_means[[col]], format = "f", digits = 2)
)
}
# Create short table
df_grouped_means_short <- df_grouped_means[df_grouped_means$Variable %in% vars_short,]
df_grouped_means_short <- df_grouped_means_short %>%
mutate(Variable = factor(Variable, levels = vars_short)) %>%
arrange(Variable) %>%
mutate(Variable = as.character(Variable))
df_grouped_means_short$Variable <- map_varnames[df_grouped_means_short$Variable]
kmeans_results[[set_name]][['short']] <- df_grouped_means_short
# Create long table
df_grouped_means_long <- df_grouped_means[!df_grouped_means$Variable %in% c(
"welfare_adjusted", "welfare_unadjusted"), ]
match_idx <- match(df_grouped_means_long$Variable, vars_short)
original_order <- seq_len(nrow(df_grouped_means_long))
df_grouped_means_long <- df_grouped_means_long[order(is.na(match_idx), match_idx, original_order), ]
df_grouped_means_long$Variable <- map_varnames[df_grouped_means_long$Variable]
rownames(df_grouped_means_long) <- NULL
kmeans_results[[set_name]][['long']] <- df_grouped_means_long
if(save){
kmeans_export_latex_short <- kable(
df_grouped_means_short, format = "latex", escape = T, booktabs=T, linesep = "",
caption = "Covariate means of winners and losers from fairness-based reassignment",
label = paste0("tab:kmeans_short_", set_name), align=paste0("l", strrep("r", n_clusters)), full_width = T,
latex_header_includes = c("\\renewcommand{\\arraystretch}{2}"))%>%
kable_styling(latex_options = c("HOLD_position"), font_size = 8) %>%
add_header_above(c(" " = 1, "Cluster (sorted by welfare change)" = n_clusters), bold = T, line=T) %>%
footnote(general = note, footnote_as_chunk=T, general_title="", threeparttable = T, escape = FALSE) %>%
row_spec(c(2,4,7), hline_after = TRUE) %>%
column_spec(2:(n_clusters+1), width = "1.5cm")
kmeans_export_latex_short <- gsub("midrule\\\\", "midrule", kmeans_export_latex_short, fixed = TRUE)
writeLines(kmeans_export_latex_short, paste0(RESULTS_PATH, "kmeans_short_", set_name,".tex"))
kmeans_export_latex_long <- kable(
df_grouped_means_long, format = "latex", escape = T, booktabs=T, linesep = "",
caption = "Covariate means of winners and losers from fairness-based reassignment (all covariates)",
label = paste0("tab:kmeans_long_", set_name), align=paste0("l", strrep("r", n_clusters)), full_width = T,
latex_header_includes = c("\\renewcommand{\\arraystretch}{2}"))%>%
kable_styling(latex_options = c("HOLD_position"), font_size = 8) %>%
add_header_above(c(" " = 1, "Cluster (sorted by welfare change)" = n_clusters), bold = T, line=T) %>%
footnote(general = note, footnote_as_chunk=T, general_title="", threeparttable = T, escape = FALSE) %>%
row_spec(c(2,4,7), hline_after = TRUE) %>%
column_spec(2:(n_clusters+1), width = "1.5cm")
kmeans_export_latex_long <- gsub("midrule\\\\", "midrule", kmeans_export_latex_long, fixed = TRUE)
writeLines(kmeans_export_latex_long, paste0(RESULTS_PATH, "kmeans_long_", set_name,".tex"))
}
}
save.image("D:/Fabian_Muny/Results_fair/R workspaces/workspace_25_06_09_application0131.RData")
